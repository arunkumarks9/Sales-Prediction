{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082e166f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandl\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\sandl\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91761823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Downloads/amz_us_price_prediction_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc26b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1735414, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f8d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title\"] = df[\"title\"] + \". \" + df[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8adc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"title\", \"stars\", \"isBestSeller\", \"boughtInLastMonth\", \"price\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fc5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = \"isBestSeller\"\n",
    "le = LabelEncoder()\n",
    "df[categories] = le.fit_transform(df[categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dc0e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals = [\"stars\", \"boughtInLastMonth\", \"price\"]\n",
    "norm = Normalizer()\n",
    "df[numericals] = norm.fit_transform(df[numericals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7947dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b44e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def extract_tokens(x):\n",
    "    for txt, _, _, _, _ in x:\n",
    "        yield tokenizer(txt)\n",
    "        \n",
    "        \n",
    "vocab = build_vocab_from_iterator(extract_tokens(df.values), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ef62e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a2d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    text, numericals, target, offsets = [], [], [], [0]\n",
    "    for txt, stars, seller, bought, price in batch:\n",
    "        processed_text = torch.tensor(text_pipeline(txt))\n",
    "        text.append(processed_text)\n",
    "        numericals.append([stars, seller, bought])\n",
    "        target.append(price)\n",
    "        offsets.append(processed_text.size(0))\n",
    "        \n",
    "    text = torch.cat(text)\n",
    "    numericals = torch.tensor(numericals)\n",
    "    target = torch.tensor(target)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    \n",
    "    return text, numericals, target, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4695bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_phase, testing = train_test_split(df.values, random_state=42, test_size=0.2)\n",
    "train, val = train_test_split(training_phase, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb020916",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 128\n",
    "LR = 0.1\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4e7beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train, batch_size=BATCH, shuffle=True, collate_fn=collate)\n",
    "val_dl = DataLoader(val, batch_size=BATCH, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21c0ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Price(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, feat_size):\n",
    "        super(Price, self).__init__()\n",
    "        self.embed = nn.EmbeddingBag(vocab_size, embed_size)\n",
    "        self.layer = nn.Sequential(nn.Linear(embed_size, 512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm1d(512),\n",
    "                                  nn.Linear(512, 256),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm1d(256),\n",
    "                                  nn.Linear(256, feat_size),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm1d(feat_size))\n",
    "        \n",
    "        self.fc = nn.Linear(feat_size*2, 1)\n",
    "        \n",
    "    def forward(self, x, nums, off):\n",
    "        x = self.embed(x, off)\n",
    "        x = self.layer(x)\n",
    "        x = torch.cat((x, nums), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return nn.functional.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eb06b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_size = 256\n",
    "feats = len(numericals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dc70a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b20ace63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Price(vocab_size, embed_size, feats)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2af21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandl\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\sandl\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([55])) that is different to the input size (torch.Size([55, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\sandl\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([115])) that is different to the input size (torch.Size([115, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss 0.0013114311904987872 val loss 0.0013117852678397387\n",
      "Epoch 2 train loss 0.0013050373146411794 val loss 0.0013086697098350746\n",
      "Epoch 3 train loss 0.0013050795582389473 val loss 0.001309809182865362\n"
     ]
    }
   ],
   "source": [
    "best_model = deepcopy(model)\n",
    "best_loss = 10e9\n",
    "train_history = []\n",
    "val_history  = []\n",
    "\n",
    "for i in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    for txt, nums, target, off in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        if torch.cuda.is_available():\n",
    "            txt, nums, target, off = txt.cuda(), nums.cuda(), target.cuda(), off.cuda()\n",
    "        \n",
    "        out = model(txt, nums, off)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_total += out.size(0)\n",
    "    train_loss = train_loss/train_total\n",
    "    train_history += [train_loss]\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for txt, nums, target, off in val_dl:\n",
    "            if torch.cuda.is_available():\n",
    "                txt, nums, target, off = txt.cuda(), nums.cuda(), target.cuda(), off.cuda()\n",
    "\n",
    "            out = model(txt, nums, off)\n",
    "            loss = criterion(out, target)\n",
    "            val_loss += loss.item()\n",
    "            val_total += out.size(0)\n",
    "            \n",
    "    val_loss = val_loss/val_total\n",
    "    val_history += [val_loss]\n",
    "    if val_loss < best_loss:\n",
    "        best_model = deepcopy(model)\n",
    "        best_loss = val_loss\n",
    "        \n",
    "    print(\"Epoch {} train loss {} val loss {}\".format(i, train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e856e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(1, EPOCHS+1))\n",
    "plt.plot(epochs, train_history)\n",
    "plt.plot(epochs, val_history)\n",
    "plt.legend([\"training\", \"validation\"])\n",
    "plt.title(\"Training performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d04909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    txt, stars, seller, bought, price = x\n",
    "    processed = torch.tensor(text_pipeline(txt))\n",
    "    numericals = [[stars, seller, bought]]\n",
    "    numericals = torch.tensor(numericals)\n",
    "    off = torch.tensor([0])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if torch.cuda.is_available():\n",
    "            processed, numericals, off = processed.cuda(), numericals.cuda(), off.cuda()\n",
    "        out = model(processed, numericals, off)\n",
    "            \n",
    "    return out.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d81a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "real = []\n",
    "for i in range(len(testing)):\n",
    "    predicted += [predict(testing[i])]\n",
    "    real += [testing[i, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(real, predicted)\n",
    "mae = mean_absolute_error(real, predicted)\n",
    "r2 = r2_score(real, predicted)\n",
    "\n",
    "print(\"MSE: {}\\nMAE: {}\\nr2 score: {}\".format(mse, mae, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3eb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
